{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf5c3558",
   "metadata": {},
   "source": [
    "# Ensemble combine with logistic regression\n",
    "\n",
    "Aim: To combine output from logistic regression, random forests, and neural network models in a single logistic regression model, with or without original features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c795a",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ec1ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn warnings off to keep notebook tidy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5991a6",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f2f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./../data/10k_training_test/cohort_10000_train.csv')\n",
    "test = pd.read_csv('./../data/10k_training_test/cohort_10000_test.csv')\n",
    "model_probs_train = pd.read_csv(\n",
    "    './individual_model_output/probabilities_train.csv')\n",
    "model_probs_test = pd.read_csv(\n",
    "    './individual_model_output/probabilities_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08635d79",
   "metadata": {},
   "source": [
    "## Function to standardise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd598b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_data(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Converts all data to a similar scale.\n",
    "    Standardisation subtracts mean and divides by standard deviation\n",
    "    for each feature.\n",
    "    Standardised data will have a mena of 0 and standard deviation of 1.\n",
    "    The training data mean and standard deviation is used to standardise both\n",
    "    training and test set data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc = StandardScaler() \n",
    "\n",
    "    # Set up the scaler just on the training set\n",
    "    sc.fit(X_train)\n",
    "\n",
    "    # Apply the scaler to the training and test sets\n",
    "    train_std=sc.transform(X_train)\n",
    "    test_std=sc.transform(X_test)\n",
    "    \n",
    "    return train_std, test_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6918cbc1",
   "metadata": {},
   "source": [
    "## Fit a model using original training data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc6b001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.834\n",
      "Test accuracy: 0.832\n"
     ]
    }
   ],
   "source": [
    "# Set up train and test data\n",
    "X_train = train.drop('S2Thrombolysis', axis=1)\n",
    "X_test = test.drop('S2Thrombolysis', axis=1)\n",
    "y_train = train['S2Thrombolysis']\n",
    "y_test = test['S2Thrombolysis']\n",
    "\n",
    "# Get X and y\n",
    "X_train = train.drop('S2Thrombolysis', axis=1)\n",
    "X_test = test.drop('S2Thrombolysis', axis=1)\n",
    "y_train = train['S2Thrombolysis']\n",
    "y_test = test['S2Thrombolysis']\n",
    "\n",
    "# One hot encode hospitals\n",
    "X_train_hosp = pd.get_dummies(X_train['StrokeTeam'], prefix = 'team')\n",
    "X_train = pd.concat([X_train, X_train_hosp], axis=1)\n",
    "X_train.drop('StrokeTeam', axis=1, inplace=True)\n",
    "X_test_hosp = pd.get_dummies(X_test['StrokeTeam'], prefix = 'team')\n",
    "X_test = pd.concat([X_test, X_test_hosp], axis=1)\n",
    "X_test.drop('StrokeTeam', axis=1, inplace=True)\n",
    "\n",
    "# Standardise X data\n",
    "X_train_std, X_test_std = standardise_data(X_train, X_test)\n",
    "\n",
    "# Define and Fit model\n",
    "model = LogisticRegression(solver='lbfgs', random_state=42)\n",
    "model.fit(X_train_std, y_train)\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_train_probs = model.predict_proba(X_train_std)[:,1]\n",
    "y_test_probs = model.predict_proba(X_test_std)[:,1]\n",
    "                                    \n",
    "# Show accuracy\n",
    "train_class = y_train_probs >= 0.5\n",
    "test_class = y_test_probs >= 0.5\n",
    "accuracy_train = np.mean(y_train == train_class)\n",
    "accuracy_test = np.mean(y_test == test_class)\n",
    "print (f'Training accuracy: {accuracy_train:0.3f}')\n",
    "print (f'Test accuracy: {accuracy_test:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925b5a57",
   "metadata": {},
   "source": [
    "## Fit a model using model probabilities only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a0d43c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.000\n",
      "Test accuracy: 0.836\n"
     ]
    }
   ],
   "source": [
    "# Set up train and test data\n",
    "\n",
    "X_train = model_probs_train\n",
    "X_test = model_probs_test\n",
    "y_train = train['S2Thrombolysis']\n",
    "y_test = test['S2Thrombolysis']\n",
    "\n",
    "# Standardise X data\n",
    "X_train_std, X_test_std = standardise_data(X_train, X_test)\n",
    "\n",
    "# Define and Fit model\n",
    "model = LogisticRegression(solver='lbfgs', random_state=42)\n",
    "model.fit(X_train_std, y_train)\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_train_probs = model.predict_proba(X_train_std)[:,1]\n",
    "y_test_probs = model.predict_proba(X_test_std)[:,1]\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_train_probs = model.predict_proba(X_train)[:,1]\n",
    "y_test_probs = model.predict_proba(X_test)[:,1]\n",
    "                                    \n",
    "# Show accuracy\n",
    "train_class = y_train_probs >= 0.5\n",
    "test_class = y_test_probs >= 0.5\n",
    "accuracy_train = np.mean(y_train == train_class)\n",
    "accuracy_test = np.mean(y_test == test_class)\n",
    "print (f'Training accuracy: {accuracy_train:0.3f}')\n",
    "print (f'Test accuracy: {accuracy_test:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5f9073",
   "metadata": {},
   "source": [
    "## Fit a model using original features and model probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cadfe930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.000\n",
      "Test accuracy: 0.839\n"
     ]
    }
   ],
   "source": [
    "# Set up train and test data\n",
    "X_train = train.drop('S2Thrombolysis', axis=1)\n",
    "X_test = test.drop('S2Thrombolysis', axis=1)\n",
    "y_train = train['S2Thrombolysis']\n",
    "y_test = test['S2Thrombolysis']\n",
    "\n",
    "# Get X and y\n",
    "X_train = train.drop('S2Thrombolysis', axis=1)\n",
    "X_test = test.drop('S2Thrombolysis', axis=1)\n",
    "y_train = train['S2Thrombolysis']\n",
    "y_test = test['S2Thrombolysis']\n",
    "\n",
    "# One hot encode hospitals\n",
    "X_train_hosp = pd.get_dummies(X_train['StrokeTeam'], prefix = 'team')\n",
    "X_train = pd.concat([X_train, X_train_hosp], axis=1)\n",
    "X_train.drop('StrokeTeam', axis=1, inplace=True)\n",
    "X_test_hosp = pd.get_dummies(X_test['StrokeTeam'], prefix = 'team')\n",
    "X_test = pd.concat([X_test, X_test_hosp], axis=1)\n",
    "X_test.drop('StrokeTeam', axis=1, inplace=True)\n",
    "\n",
    "# Add in model probabilties\n",
    "X_train = pd.concat([X_train, model_probs_train], axis=1)\n",
    "X_test = pd.concat([X_test, model_probs_test], axis=1)\n",
    "\n",
    "# Standardise X data\n",
    "X_train_std, X_test_std = standardise_data(X_train, X_test)\n",
    "\n",
    "# Define and Fit model\n",
    "model = LogisticRegression(solver='lbfgs', random_state=42)\n",
    "model.fit(X_train_std, y_train)\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_train_probs = model.predict_proba(X_train_std)[:,1]\n",
    "y_test_probs = model.predict_proba(X_test_std)[:,1]\n",
    "                                    \n",
    "# Show accuracy\n",
    "train_class = y_train_probs >= 0.5\n",
    "test_class = y_test_probs >= 0.5\n",
    "accuracy_train = np.mean(y_train == train_class)\n",
    "accuracy_test = np.mean(y_test == test_class)\n",
    "print (f'Training accuracy: {accuracy_train:0.3f}')\n",
    "print (f'Test accuracy: {accuracy_test:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68183146",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "* Including in model probability outputs from previous logistic regression, random forests, and neural networks, did not improve accuracy of the model compared to fitting a logistic regression model just on the original data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
